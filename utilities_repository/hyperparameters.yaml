# Hyperparameters for training session
Humanoid-v4:
  name: "Humanoid-v4"

  cpg:
    num_oscillators: 1
    neuron_number: 2
    tau_r: 2.0
    tau_a: 12.0

  DDPG:
    training:
      batch_size: 265
      replay_buffer_size : 8192
      learning_rate: 0.00034
      decay_lr : 0.98
      gamma: 0.97
      steps: 4000000
      learning_starts: 10000
      noise : 0.1


    model:
      neuron_number: [400, 300]
      layers_number : 2

  MPO:
    training:
      batch_size: 256
      replay_buffer_size : 16384
      learning_rate: 3.56987e-05
      gamma: 0.95
      steps: 5000000
      lr_critic : 0.0003
      lr_dual : 0.000356987
      clip_range : 0.3
      epsilon : 0.1


    model:
      neuron_number: [256, 256]
      layers_number : 2

  SAC:
    training:
      batch_size: 265
      replay_buffer_size : 8192
      learning_rate: 0.00034
      gamma: 0.95
      steps: 6000000
      learning_starts: 10000
      noise : 0.15


    model:
      neuron_number: [256, 256]
      layers_number : 2


  PPO:
    training:
      batch_size: 512
      replay_buffer_size : 4096
      learning_rate: 3.569e-4
      gamma: 0.99
      decay_lr: 0.98
      decay_factor : 0.98
      normalizer: True
      steps: 5000000
      ent_coeff : 0.0238306
      clip_range : 0.3


    model:
      neuron_number: [256, 256]
      layers_number : 2


Walker2d-v4:
  name: "Walker2d-v4"

  cpg:
    num_oscillators: 2
    neuron_number: 2

  DDPG:
    training:
      batch_size: 265
      replay_buffer_size: 4096
      learning_rate: 0.001
      gamma: 0.99
      steps: 1000000
      learning_starts: 10000
      noise: 0.1


    model:
      neuron_number: [400, 300]
      layers_number: 2

  MPO:
    training:
      batch_size: 265
      replay_buffer_size: 8192
      learning_rate: 3e-04
      gamma: 0.95
      steps: 1000000
      lr_critic: 1.5e-4
      lr_dual: 0.000156987
      clip_range: 0.1
      epsilon: 0.1


    model:
      neuron_number: [400, 300]
      layers_number: 2

  SAC:
    training:
      batch_size: 256
      replay_buffer_size: 4096
      learning_rate: 0.001
      gamma: 0.99
      steps: 2000000
      learning_starts: 10000
      noise: 0.1


    model:
      neuron_number: [400, 300]
      layers_number: 2


  PPO:
    training:
      batch_size: 32
      replay_buffer_size: 4096
      learning_rate: 3.4e-04
      gamma: 0.97
      steps: 1000000
      learning_starts: 10000
      decay_lr: 0.98
      ent_coeff: 0.000585045
      clip_range: 0.1


    model:
      neuron_number: [256, 256]
      layers_number: 2

myoAmp1DoFWalk-v0:
  cpg:
    num_oscillators: 2
    neuron_number: 2
    tau_r: 2.0
    tau_a: 12.0

  SAC:
    training:
      batch_size: 256
      replay_buffer_size: 1000000.0
      learning_rate: 0.0003
      gamma: 0.99
      steps: 1e7
      learning_starts: 20000
      noise: 0.1


    model:
      neuron_number: 256
      layers_number: 2


  PPO:
    training:
      batch_size: 256
      replay_buffer_size: 16384
      learning_rate: 3.56987e-05
      gamma: 0.98
      steps: 1e8
      learning_starts: 10000
      ent_coeff: 0.000585045
      clip_range: 0.1
      decay_lr: 0.98
      normalization: true


      neuron_number: [ 1024 512 256 ]
      layers_number: 3

  MPO:
    training:
      learning_rate: 2.54e-05
      lr_critic: 6.081e-05
      lr_dual: 0.00213
      decay_lr: 0.98
      hidden_size: 1024
      hidden_layers: 3
      discount_factor: 0.95
      gamma: 0.95
      batch_size: 256
      replay_buffer_size: 32768
      steps: 1e7

    model:
      neuron_number: [1024, 1024]
      layers_number: 2

    DEP:
      test_episode_every: 3
      kappa: 1169.7
      tau: 40
      buffer_size: 200
      bias_rate: 0.002
      s4avg: 2
      time_dist: 5
      normalization: "independent"
      sensor_delay: 1
      regularization: 32
      with_learning: true
      q_norm_selector: "l2"
      intervention_length: 5
      intervention_proba: 0.0004