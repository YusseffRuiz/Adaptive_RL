from .mpo import MPOAgent, MPOTrainer

PACKAGE_NAME = "MPO_Algorithm"
VERSION = "1.0.0"
